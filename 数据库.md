# 数据库

### 一、MySQL

##### 0.如何起sql服务以及连接数据库

```
1.以管理员身份打开cmd，执行‘net start mysql’开启sql服务；执行‘net stop mysql’关闭sql服务。
2.运行cmd，执行‘mysql -u root -p’，连接数据库
```

##### 1.使用Python操作MySQL

```python
# 六个常用参数
    1.host：MySQL服务器所在的主机IP，若在本机，则为‘localhost’
    2.user：用户名
    3.password：密码
    4.port：连接的MySQL主机的端口，默认为3306
    5.db：连接的数据库名
    6.charset：当读取数据出现中文乱码时，需要设置一下编码，默认为‘utf8’

# 热身案例
    import pymysql
    # 创建数据库对象
    db = pymysql.connect(host='localhost',user='root',password='123',
                         port=3306,db='huawei',charset='utf8')
    # 开启MySQL的游标功能，创建一个游标对象
    cursor = db.cursor()
    # 需要执行的sql语句
    sql = 'select * from student'
    # 使用游标对象执行sql语句
    cursor.execute(sql)
    # 使用fetchone()方法，获取返回结果
    data = cursor.fetchone()
    # 断开数据库连接，释放资源
    db.close()
    
# cursor游标对象的常用方法
1.cursor用来执行命令的方法
	-execute(query,args)：执行单条sql语句，接收参数为sql语句本身和使用的参数列表，返回值为受影响行数
    -executemany(query,args)：执行单条sql语句，重复执行参数列表里的参数，返回值为受影响行数
    
2.cursor用来接收返回值的方法
	-fetchone()：返回一条结果行
    -fetchmany(size)：接收size条返回结果行。如果size值大于结果行的数量，则返回cursor.arraysize条
    -fetchall()：接收全部的返回结果行
    
3.使用pandas中的read_sql()方法，将提取到的数据直接转化为DadaFrame
    import pymysql
    import pandas as pd
    db = pymysql.connect(host='localhost',user='root',password='123',
                         port=3306,db='huawei',charset='utf8')
    cursor = db.cursor()

    df1 = pd.read_sql("select * from student where sex='男'",db)
    display(df1)
    
# 插入数据
1.插入一条数据
    import pymysql
    db = pymysql.connect(host='localhost',user='root',password='123',
                         port=3306,db='huawei',charset='utf8')
    cursor = db.cursor()
    sql = 'insert into person(name,age) values(%s,%s)'
    try:
        cursor.execute(sql,('孙悟空',10000))
        db.commit()
        print('插入成功')
    except:
        print('插入失败')
        db.rollback()
    db.close()
    
2.插入多条数据
    import pymysql
    db = pymysql.connect(host='localhost',user='root',password='123',
                         port=3306,db='huawei',charset='utf8')
    cursor = db.cursor()
    sql = 'insert into person(name,age) values(%s,%s)'
    datas = [('牛魔王'，9000)，('铁扇'，8000)，('牛魔'，90000)]
    try:
        cursor.execute(sql,datas)
        db.commit()
        print('插入成功')
    except:
        print('插入失败')
        db.rollback()
    db.close()

3.通用的插入方法
    data = {'id':'2020','name':'tangtang','age':'20'}
    table = 'mine'
    keys = ','.join(data.keys())
    values = ','.join(['%s']*len(data))
    sql = 'INSERT INTO {table}({keys}) VALUES ({values})'.format(table=table,keys=keys,values=values)
    try:
        if cursor.ececute(sql,tuple(data.values())):
            print('Successful')
            db.commit()
    except:
        print('Failed')
        db.rollback()
    db.close()

4.更新数据（并去重）
    data = {'id':'2020','name':'tangtang','age':'20'}
    table = 'mine'
    keys = ','.join(data.keys())
    values = ','.join(['%s']*len(data))
    sql = 'INSERT INTO {table}({keys}) VALUES ({values}) ON DUPLICATE KEY UPDATE'.format(table=table,keys=keys,values=values)
    update = ','.join(["{key} = %s".formate(key=key) for key in data])
    sql += update
    try:
        if cursor.ececute(sql,tuple(data.values())*2):
            print('Successful')
            db.commit()
    except:
        print('Failed')
        db.rollback()
    db.close()

# 删除数据
    table = 'mine'
    condition = 'age > 20'
    sql = 'DELETE FROM {table} WHERE {condition}'.format(table=table,condition=condition)
    try:
		cursor.ececute(sql):
		print('Successful')
        db.commit()
    except:
        print('Failed')
        db.rollback()
    db.close()

# 取数据
    sql = ''
    try:
		cursor.ececute(sql,tuple(data.values())):
        print('Count:',cursor.rowcount)
        row = cursor.fetchone()  # 得到的是一个元组
        while row；
        	print('Row:',row)
            row = cursor.fetchone()
    except:
        print('Error')


    
    
# 总结
	1.pymysql模块是默认开启MySQL的事务功能的，因此，进行‘增、删、改’的时候，一定要使用commit()提交事务
    2.进行‘增、删、改’的时候，一定要使用try...except...语句
    


```



##### 4.scrapy连接MySQL

```python
# settings文件设置
    MYSQL_HOST = 'localhost'
    MYSQL_DBNAME = 'scrapy'
    MYSQL_USER = 'root'
    MYSQL_PASSWD = '123456'
    MYSQL_PORT = 3306
    
# pipeline文件
import pymysql
import datetime
from tutorial import settings
import logging

class TutorialPipeline(object):
    def __init__(self):
        self.connect = pymysql.connect(host = settings.MYSQL_HOST,
                                       db = settings.MYSQL_DBNAME,
                                       user = settings.MYSQL_USER,
                                       passwd = settings.MYSQL_PASSWD,
                                       charset = 'utf8',
                                       use_unicode = True)
        self.cursor = self.connect.cursor()

    def process_item(self, item, spider):
        try:
            self.cursor.execute(
                "insert into article (body, author, createDate) value(%s, %s, %s) on duplicate key update author=(author)",
                (item['body'],
                 item['author'],
                 datetime.datetime.now()
                 ))
            self.connect.commit()
        except Exception as error:
            logging.log(error)
        return item

    def close_spider(self, spider):
        self.connect.close()
```

##### 5.爬虫数据使用MySQL保存时自动过滤重复数据

```sql
# 方法一
使用插入更新语句：on duplicate key update
语法：
INSERT INTO tablename(field1,field2, field3, ...) VALUES(value1, value2, value3, ...) ON DUPLICATE KEY UPDATE field1=value1,field2=value2, field3=value3, ...;
目的是为了解决重复性，当数据库中存在某个记录时，执行这条语句会更新它，而不存在这条记录时，会插入它。
语句规则如下：如果你插入的记录导致一个UNIQUE索引或者primary key(主键)出现重复，那么就会认为该条记录存在，则执行update语句而不是insert语句，反之，则执行insert语句而不是更新语句。

# 方法二
使用关键字：ignore
规则：若有导致unique key冲突的记录，则该条记录不会插入到数据库中
语法：
INSERT IGNORE INTO tablename(field1,field2 ...) VALUES(value1, value2 ...);
```



### 二、MongoDB

##### 1.数据库服务的启动（一个窗口）

```python
1.在bin目录下
2.shift + 右键，打开powershell窗口，执行以下命令：
	mongod --dbpath 'db文件路径' 或 .\mongod --dbpath 'db文件路径'
4.检查是否启动成功：
	浏览器访问localhost:27017
```

##### 2.客户端启动（一个窗口）

```python
1.在bin目录下
2.shift + 右键，打开powershell窗口，执行以下命令：
	mongo 或 .\mongo  ---启动客户端，进入命令交互模式
```

##### 3.python操作mongodb

```python
import pymongo

client = pymongo.MongoClient('localhost',27017,connect=False)  # 采用多进程时，消除警告信息
db = client['库名']  # 在 MongoDB 中，数据库只有在内容插入后才会创建!
col = db['集合名']   # 在 MongoDB 中，集合只有在内容插入后才会创建!
```

##### 4.scrapy连接mongodb

```python
import pymongo

class MongoPipeline(object):

    def __init__(self):
        self.client = pymongo.MongoClient('localhost', 27017, connect=False) 
        self.db = self.client['58zufang']  
        self.col = self.db['58zufang']

    def process_item(self, item, spider):
        self.col.insert(dict(item))
        return item
```

##### 5.爬虫数据使用MongoDB保存时自动过滤重复数据

```python
尽量使用update_one()方法而不是insert_one()插入数据
    def process_item(self, item, spider):
        self.col.update_one(item,{'$set':item},upsert=True)
        return item
```



### 三、Redis

##### 1.数据库服务的启动（一个窗口）

```python
1.打开一个cmd窗口，使用cd命令切换到redis目录下或在redis文件内，shift+右键，执行powershell窗口：
	.\redis-server.exe redis.window.conf
    可以把redis的路径加到系统的环境变量，后面的redis.windows.conf可以省略。
```

##### 2.客户端启动（一个窗口）

```python
1.打开一个cmd窗口，使用cd命令切换到redis目录下/在redis文件内，shift+右键，执行powershell窗口：
	.\redis-cli.exe -h 127.0.0.1 -p 6379   ---客户端启动
```

##### 3.python操作redis

```python
redis-py提供两个类Redis和StrictRedis用于实现Redis的命令，StrictRedis用于实现大部分官方的命令，并使用官方的语法和命令，Redis是StrictRedis的子类，用于向后兼容旧版本的redis-py。

import redis
  
r = redis.Redis(host='127.0.0.1', port=6379)
r.set('foo', 'Bar')
print(r.get('foo'))

# 连接池
redis-py使用ConnectionPool来管理对一个redis server的所有连接，避免每次建立、释放连接的开销。
默认，每个Redis实例都会维护一个自己的连接池。
可以直接建立一个连接池，然后作为参数Redis，这样就可以实现多个Redis实例共享一个连接池。

import redis

pool = redis.ConnectionPool(host='127.0.0.1', port=6379)
  
r = redis.Redis(connection_pool=pool)
r.set('foo', 'Bar')
print(r.get('foo'))
```

### 四、数据库优化

```python
1.根据服务层面 
	配置mysql性能优化参数；
    	https://www.cnblogs.com/angryprogrammer/p/6667741.html
---------------------------------------------------------------------------------------   
2.从系统层面增强mysql的性能：
	优化数据表结构 
	2.1.将字段较多的表分解成多个表 
		对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。因为当一个表的数据量很大时，会由于存在使用频率低的字段而使查询速度变慢。 
	2.2.增加中间表 
		对于经常需要联合查询的表，可以建立中间表以提高查询效率。通过建立中间表，把需要经常联合查询的数据插入中间表，然后将原来的联合查询改为对中间表的查询，以此来提高查询效率。 
    2.3.选取最适用的字段属性
    	在创建表的时候，为了获得更好的性能，我们可以将表中字段的宽度设得尽可能小。
        在可能的情况下，应该尽量把字段设置为NOTNULL，这样在将来执行查询的时候，数据库不用去比较NULL值。
        将字段属性尽可能的定义为数值型；
        在MySQL中，enumerate类型被当作数值型数据来处理，数值型数据被处理起来的速度要比文本类型快得多。
    2.4.合理建立索引
    	一般说来，索引应建立在那些将用于JOIN,WHERE判断和ORDERBY排序的字段上；
        不要建立无用索引，会影响数据库插入和更新的效率；
---------------------------------------------------------------------------------------   
3.从数据库层面增强性能 
	优化SQL语句，合理使用字段索引。 
    使用连接（JOIN）来代替子查询(Sub-Queries)
    
---------------------------------------------------------------------------------------   
4.从应用层面增强性能
	使用缓存和NoSQL数据库方式存储，如MongoDB/Memcached/Redis来缓解高并发下数据库查询的压力。
    
---------------------------------------------------------------------------------------   
5.提升数据库服务器硬件配置，或者搭建数据库集群

```

```sql
# Limit分页查询性能优化
	原SQL语句如下：
		select * from mytbl order by id limit 100000,10  
	改进后的SQL语句如下：
      select * from mytbl where id >= ( select id from mytbl order by id limit 100000,1 ) limit 10  
      注：假设id是主键索引，那么里层走的是索引，外层也是走的索引，所以性能大大提高；
```

### 五、数据库面试题

##### 1.你了解mysql数据库查询缓存吗？

```python
配置文件在 /etc/mysql/my.cnf
# mysql数据库查询缓存总结
查询缓存（Query Cache，简称QC），存储SELECT语句及其产生的数据结果。
```

![数据库查询缓存](C:\Users\mutang\Desktop\python\数据库查询缓存.jpeg)

```python
# 查询缓存工作原理如下
- 缓存select操作的结果集和SQL语句，key为SQL，value为查询结果集；
- 如果新的select语句到了，就以这个SQL为key去缓存中查询，如果匹配，就把缓存的结果集返回；
    # 匹配标准：
        （1）在检查缓存的时候，MySQL 不会对语句进行解析、正则化或者参数化，它精确地使用客户端传来的查询语句和其他数据。只要字符大小写、空格或者注释有一点点不同，查询缓存就认为这是一个不同的查询；
		（2）查询缓存不会存储有不确定结果的查询。因此，任何一个包含不确定函数（比如NOW()）的查询不会被缓存。事实上，查询缓存不会缓存引用了用户自定义函数、存储函数、用户自定义变量、临时表、mysql 数据库中的表或者任何一个有列级权限的表的查询；
		（3）查询必须是完全相同的(逐字节相同)才能够被认为是相同的。另外，同样的查询字符串由于其它原因可能认为是不同的。使用不同的数据库、不同的协议版本或者不同 默认字符集的查询被认为是不同的查询并且分别进行缓存。

- 查看mysql设置参数，执行：
	show variables like '%query_cache%';
    # 相关参数
    query_cache_type：0-不启用查询缓存；1-启用，2-启用，默认值为0；
    	- 为1，只要符合查询缓存的要求，查询语句和记录集都可以缓存起来，SQL中加上SQL_NO_CACHE将不缓存；
		- 为2，只要SQL中添加了参数：SQL_CACHE，且符合查询缓存的要求，查询语句和记录集则可以缓存起来。
        - 格式
        	SELECT SQL_CACHE ... FROM ... WHERE ...
			SELECT SQL_NO_CACHE ... FROM ... WHERE ...
	query_cache_size：设置缓存区总大小，允许设置最小值为40K，默认1M，推荐设置为：64M/128M；
	query_cache_limit：限制缓存区最大能缓存的单条查询记录集大小，默认设置为1M；
    
- 查看缓存使用情况，执行：
	show status like '%Qcache%%';
    # 相关参数
    Qcache_hits：缓存命中次数；
	Qcache_inserts：缓存中插入次数，每缓存一次加1，注意这个不是缓存数量；
    
- 重置缓存内容，执行：
	reset query cache;
```

![查询1](C:\Users\mutang\Desktop\python\查询1.jpeg)

![查询2](C:\Users\mutang\Desktop\python\查询2.jpeg)

```python
# 开启查询缓存
设置选项query_cache_type = 1 ，同时设置query_cache_size = 67108864；
注： query_cache_size的值设置在100MB以内即可。
	在MySQL里查询缓存是由一个全局锁在控制，每次更新查询缓存的内存块都需要进行锁定。

# 关闭查询缓存
设置选项query_cache_type = 0，同时设置query_cache_size = 0。
```

```python
# 适用场景
用于频繁提交同一个语句，并且该表数据变化不是很频繁的场景，
例如一些静态页面，或者页面中的某块不经常发生变化的信息。

由于查询缓存需要缓存最新数据结果，因此表数据发生任何变化（insert、update、delete或其他可能产生数据变化的操作），都会导致查询缓存被刷新。因而，对于一个更新频率非常低而只读查询频率非常高的场景下，打开查询缓存还是比较有优势的。

# 不适合场景
    -子查询；
    -过程、函数、触发器、event中调用的SQL，或者引用到这些结果的；
    -查询中涉及一些特殊函数时，例如：BENCHMARK()、CURDATE()、CURRENT_TIME()、CURRENT_TIMESTAMP()、NOW()、SLEEP()、CONNECTION_ID()、CURRENT_DATE()、CURRENT_USER()、PASSWORD()、RAND()、UUID()、ENCRYPT()、LAST_INSERT_ID()等等；
    -查询涉及到mysql，information_schema或performance_schema。
    类似SELECT…LOCK IN SHARE MODE、SELECT…FOR UPDATE、SELECT..INTO OUTFILE/DUMPFILE、SELECT * FROM ... WHERE autoincrement_col IS NULL的查询；
    -SELECT执行计划用到临时表；
    -未引用任何表的查询，例如SELECT 1+2；
    -查询产生了告警(warnings)；
    -SELECT语句中存在SQL_NO_CACHE关键字；
    -涉及到分区表。
```































