## 1.字体反爬流程

##### 0.1安装模块

```python
pip install fonttools

# 导入模块
from fontTolls.ttLib import TTFont
```

##### 0.2字体解析工具

```
https://font.qqe2.com/
```

##### 0.3fonttools基本使用

```python
# 打开example.woff字体文件
font = TTFont('example.woff')

# 将字体文件保存为xml文件
font.saveXML('example.xml')

# 获取字体文件中unicode名称（有序）
font.getGlyphOrder()

# 获取Unicode与name的映射关系（无序）
font.getBestCmap()

# 获取字体的轮廓信息（坐标数据）
font['glyf']['unicode'].coordinates
```

##### 0.4主要的两种字体反爬

```python
# 第一种：不同的字体文件，相同的字形
1.针对目标网站，手动建立字体基准参照字典，格式如下：
    contour为字体轮廓信息
    base_glyph = {
        md5(contour) : {'value': 1, 'unicode': 'unicxxx'},
        md5(contour) : {'value': 2, 'unicode': 'unicxxx'},
        md5(contour) : {'value': 3, 'unicode': 'unicxxx'},
    }
    # 代码
	base_glyph = {}
    font = TTFont('tadName.woff')
    font_unicode = font.getGlyphOrder()
    font_char = ['字体文件中的字构成的列表（有序）']
	for unicode, char in zip(font_unicode, font_char):
        # 取字形坐标
        contour = bytes(str(font['glyf'][unicode].coordinates),encoding='utf-8')
        # 取字形坐标的md5值
        contour_md5 = hashlib.md5(contour).hexdigest()
        # 保存到新的基准参照字典
        base_glyph[contour_md5] = {'value':char, 'unicode':unicode}
        
2.请求新的字体文件，依据基准参照字典，构建新的字体映射字典
	可以通过判定字体轮廓信息是否相等，来构建新的映射字典。
    # 代码
    new_base_glyph = {}
    new_font = TTFont('new.woff')
    # 取新字体文件中unicode
    new_unicodes = new_font.getGlyphOrder()
    # 遍历基准字典
    for new_unicode in new_unicodes:
        contour = bytes(str(new_font['glyf']['new_unicode'].coordinates),encoding='utf-8')
        new_contour_md5 = hashlib.md5(contour).hexdigest()
        for base_contour_md5 in base_glyph.key():
            if base_contour_md5 == new_contour_md5:
                new_base_glyph[base_contour_md5]['unicode'] = new_unicode
                break
            	   
3.从源码中匹配出需要替换的字体Unicode码，依据对应的字体映射字典进行替换，完事 
```

```python
# 第二种：不同的字体文件，不同的字形
可通过Knn算法，即K近邻算法解决。
1.导入模块
	import numpy as np
  基本使用：
		np.zeros()：生成相应大小的零矩阵
    	np.tile()：将数组沿各个方向复制，(1,3)横向复制，(3,1)纵向复制
        np.argsort()：将数组的值从小到大排序后，并输出对应的索引值的数组
        
2.准备数据集
	针对目标网站，构建如下格式的数据集；
    dataset = [
        [1, [字形坐标]],
        [2, [字形坐标]],
        [3, [字形坐标]],
        [4, [字形坐标]],
        [5, [字形坐标]],
        ...
    ]
3.核心思想：一般是取目标网站的几套字体文件，构成dataset（比如一个字体文件有10个数字，取5套，那么dataset的维度就是50），然后取请求新的字体文件，获得字体的轮廓信息（这一步要注意把字体轮廓信息构建成一维的列表），然后根据dataset的维度扩维，然后进行距离计算，再按距离从小到大进行排序，取前k个数，其中出现次数最多的数就是对应的明文数字。
```

```python
# KNN算法实现字体解密
import numpy as np

class KNN(object):
    def __init__(self):
        self.dataset = [
            [1, ['字形坐标']],
            [2, ['字形坐标']],
            [3, ['字形坐标']],
            [4, ['字形坐标']],
            [5, ['字形坐标']],
        ]

    def get_dataset(self):
        """
        获取数据集
        :return:
        """
        real_nums_list = [data[0] for data in self.dataset]
        base_contours_list = [data[1] for data in self.dataset]
        base_contours_array = np.zeros([50, 150])  # 50指的是dataset的维度，150指的是每一个元素的长度
        for index, base_contour in enumerate(base_contours_list):
            base_contours_array[index, :len(base_contour)] = base_contour
        return base_contours_array, real_nums_list

    def get_num(self, contour, base_contours_array, real_nums_list, k=5):
        # 先将contour与base_contours_array统一纬度：比如base_contours_array的维度为50，也就是有50行，那将需要contour复制50行
        new_array = np.tile(contour, (50, 1))
        # 求差值
        diff = new_array - base_contours_array
        # 求平方
        sqrt = diff ** 2
        # 求累加和
        sum_sqrt = sqrt.sum(axis=1)
        # 在开方
        distance = sum_sqrt ** 0.5
        # 按从小到大排序，输出元素在原列表中的索引值组成的列表
        sort_index_list = np.argsort(distance)

        count_num = {}
        for i in range(k):
            num = real_nums_list[sort_index_list[i]]
            count_num[num] = count_num.get(num, 0) + 1
        count_list = sorted(count_num.items(), key=lambda x: x[1], reverse=True)
        return count_list[0][0]

    def run(self, contour):
        base_contours_array, real_nums_list = self.get_dataset()
        self.get_num(contour, base_contours_array, real_nums_list, 5)

if __name__ == '__main__':
    my_knn = KNN()
    contour = []
    my_knn.run(contour)

```







### 资源：

##### 大众点评字体文件的字

```python
font_char = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '店', '中', '美', '家', '馆', '小', '车', '大', '市', '公', '酒',
             '行', '国', '品', '发', '电', '金', '心', '业', '商', '司', '超', '生', '装', '园', '场', '食', '有', '新', '限', '天', '面',
             '工', '服', '海', '华', '水', '房', '饰', '城', '乐', '汽', '香', '部', '利', '子', '老', '艺', '花', '专', '东', '肉', '菜',
             '学', '福', '饭', '人', '百', '餐', '茶', '务', '通', '味', '所', '山', '区', '门', '药', '银', '农', '龙', '停', '尚', '安',
             '广', '鑫', '一', '容', '动', '南', '具', '源', '兴', '鲜', '记', '时', '机', '烤', '文', '康', '信', '果', '阳', '理', '锅',
             '宝', '达', '地', '儿', '衣', '特', '产', '西', '批', '坊', '州', '牛', '佳', '化', '五', '米', '修', '爱', '北', '养', '卖',
             '建', '材', '三', '会', '鸡', '室', '红', '站', '德', '王', '光', '名', '丽', '油', '院', '堂', '烧', '江', '社', '合', '星',
             '货', '型', '村', '自', '科', '快', '便', '日', '民', '营', '和', '活', '童', '明', '器', '烟', '育', '宾', '精', '屋', '经',
             '居', '庄', '石', '顺', '林', '尔', '县', '手', '厅', '销', '用', '好', '客', '火', '雅', '盛', '体', '旅', '之', '鞋', '辣',
             '作', '粉', '包', '楼', '校', '鱼', '平', '彩', '上', '吧', '保', '永', '万', '物', '教', '吃', '设', '医', '正', '造', '丰',
             '健', '点', '汤', '网', '庆', '技', '斯', '洗', '料', '配', '汇', '木', '缘', '加', '麻', '联', '卫', '川', '泰', '色', '世',
             '方', '寓', '风', '幼', '羊', '烫', '来', '高', '厂', '兰', '阿', '贝', '皮', '全', '女', '拉', '成', '云', '维', '贸', '道',
             '术', '运', '都', '口', '博', '河', '瑞', '宏', '京', '际', '路', '祥', '青', '镇', '厨', '培', '力', '惠', '连', '马', '鸿',
             '钢', '训', '影', '甲', '助', '窗', '布', '富', '牌', '头', '四', '多', '妆', '吉', '苑', '沙', '恒', '隆', '春', '干', '饼',
             '氏', '里', '二', '管', '诚', '制', '售', '嘉', '长', '轩', '杂', '副', '清', '计', '黄', '讯', '太', '鸭', '号', '街', '交',
             '与', '叉', '附', '近', '层', '旁', '对', '巷', '栋', '环', '省', '桥', '湖', '段', '乡', '厦', '府', '铺', '内', '侧', '元',
             '购', '前', '幢', '滨', '处', '向', '座', '下', '県', '凤', '港', '开', '关', '景', '泉', '塘', '放', '昌', '线', '湾', '政',
             '步', '宁', '解', '白', '田', '町', '溪', '十', '八', '古', '双', '胜', '本', '单', '同', '九', '迎', '第', '台', '玉', '锦',
             '底', '后', '七', '斜', '期', '武', '岭', '松', '角', '纪', '朝', '峰', '六', '振', '珠', '局', '岗', '洲', '横', '边', '济',
             '井', '办', '汉', '代', '临', '弄', '团', '外', '塔', '杨', '铁', '浦', '字', '年', '岛', '陵', '原', '梅', '进', '荣', '友',
             '虹', '央', '桂', '沿', '事', '津', '凯', '莲', '丁', '秀', '柳', '集', '紫', '旗', '张', '谷', '的', '是', '不', '了', '很',
             '还', '个', '也', '这', '我', '就', '在', '以', '可', '到', '错', '没', '去', '过', '感', '次', '要', '比', '觉', '看', '得',
             '说', '常', '真', '们', '但', '最', '喜', '哈', '么', '别', '位', '能', '较', '境', '非', '为', '欢', '然', '他', '挺', '着',
             '价', '那', '意', '种', '想', '出', '员', '两', '推', '做', '排', '实', '分', '间', '甜', '度', '起', '满', '给', '热', '完',
             '格', '荐', '喝', '等', '其', '再', '几', '只', '现', '朋', '候', '样', '直', '而', '买', '于', '般', '豆', '量', '选', '奶',
             '打', '每', '评', '少', '算', '又', '因', '情', '找', '些', '份', '置', '适', '什', '蛋', '师', '气', '你', '姐', '棒', '试',
             '总', '定', '啊', '足', '级', '整', '带', '虾', '如', '态', '且', '尝', '主', '话', '强', '当', '更', '板', '知', '己', '无',
             '酸', '让', '入', '啦', '式', '笑', '赞', '片', '酱', '差', '像', '提', '队', '走', '嫩', '才', '刚', '午', '接', '重', '串',
             '回', '晚', '微', '周', '值', '费', '性', '桌', '拍', '跟', '块', '调', '糕']
```

## 2.构建headers注意点

```python
ValueError: Invalid header name b':authority'
    
请求头含有‘:’，是解析不了的，直接删除掉
```

## 3.pymysql连接MySQL注意点

```
pymysql.connect中的charset的内容为'utf8'，而不是'utf-8'
端口port为整形，而不是字符串！！！！
```

## 4.什么是浏览器指纹检查技术？

```
基于浏览器的useragent字段描述的浏览器品牌，版本号信息，对js运行时、DOM和BOM的各个原生对象的属性及方法进行检验，观察其特征是否符合该版本的浏览器所应具备的特征，这种方式被称为‘浏览器指纹检查技术’。依托于大型web站对各型号浏览器api信息的收集。
浏览器指纹技术常用于客户端跟踪及反机器人的场景。核心思路是， 不同浏览器、操作系统、以及操作系统环境，会使得canvas的同一绘图操作流程产生不同的结果。如果是相同的运行环境，同一套Canvas操作流程会产生相同的结果。 浏览器指纹的优势是不需要浏览器保持本地状态，即可跟踪浏览器。
```

## 5.反爬虫机制

```python
1.封IP
2.HTTP协议层几个HTTP头：referer/User-Agent/Host等
3.验证码
4.JS渲染
5.接口加密与JS混淆
6.脏数据
7.行为分析
8.windows.navigator对象检测
	浏览器中Windows.navigator对象保持着很多的操作系统和浏览器信息。
9.假链陷阱
	思路是构建一个不可见的<a>标签，如果爬虫跟踪所有的页面链接，势必会命中反爬陷阱。
10.浏览器指纹
	核心思路是，不同浏览器、操作系统、以及操作系统环境，会使得canvas的同一绘图操作流程产生不同的结果。
	如果是相同的运行环境，同一套Canvas操作流程会产生相同的结果。
11.JS引擎指纹
	不同的JS引擎在执行相同的JS语句时，会有不同的结果。 
	举个例子来说，eval.toString().length，
	在Safari浏览器中的结果是37,在IE中是39,在Chrome中的结果是33. 
	通过判断JS引擎的动作和UserAgent中声称的浏览器类型，可以判断是否是伪造浏览器。
12.字体加密
13.CSS偏移字体反爬
14.图片懒加载
```





























































































